{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcxiP308kG3z",
        "outputId": "0bbd19ae-af50-447e-ffbe-d774884db2de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyjanitor\n",
            "  Downloading pyjanitor-0.22.0-py3-none-any.whl (135 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 40 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 92 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 135 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from pyjanitor) (5.5.0)\n",
            "Collecting pandas-flavor\n",
            "  Downloading pandas_flavor-0.3.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting multipledispatch\n",
            "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyjanitor) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch->pyjanitor) (1.15.0)\n",
            "Collecting pandas-flavor\n",
            "  Downloading pandas_flavor-0.2.0-py2.py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from pandas-flavor->pyjanitor) (0.18.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas-flavor->pyjanitor) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-flavor->pyjanitor) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-flavor->pyjanitor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-flavor->pyjanitor) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.4 in /usr/local/lib/python3.7/dist-packages (from xarray->pandas-flavor->pyjanitor) (57.4.0)\n",
            "Installing collected packages: pandas-flavor, multipledispatch, pyjanitor\n",
            "Successfully installed multipledispatch-0.6.0 pandas-flavor-0.2.0 pyjanitor-0.22.0\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyjanitor\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vannZwMPj_S5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import janitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqW-AmKheees",
        "outputId": "8cab8cc5-9d53-45d2-dc87-271448ffb907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 23.3M  100 23.3M    0     0  28.2M      0 --:--:-- --:--:-- --:--:-- 28.2M\n",
            "Archive:  NRC-Emotion-Lexicon.zip\n",
            "   creating: NRC-Emotion-Lexicon/\n",
            "  inflating: __MACOSX/._NRC-Emotion-Lexicon  \n",
            "  inflating: NRC-Emotion-Lexicon/EmoLex-Ethics-Data-Statement.pdf  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/._EmoLex-Ethics-Data-Statement.pdf  \n",
            "  inflating: NRC-Emotion-Lexicon/.DS_Store  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/._.DS_Store  \n",
            "   creating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/\n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/._NRC-Emotion-Lexicon-v0.92  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC - Sentiment Lexicon - Research EULA Sept 2017 .pdf  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/._NRC - Sentiment Lexicon - Research EULA Sept 2017 .pdf  \n",
            "  inflating: NRC-Emotion-Lexicon/README.txt  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/._README.txt  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/.DS_Store  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._.DS_Store  \n",
            "   creating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Older Versions/\n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._Older Versions  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Paper1_NRC_Emotion_Lexicon.pdf  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._Paper1_NRC_Emotion_Lexicon.pdf  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Paper3-EthicalConsiderations.pdf  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._Paper3-EthicalConsiderations.pdf  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/readme.txt  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._readme.txt  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Senselevel-v0.92.txt  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Paper2_NRC_Emotion_Lexicon.pdf  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._Paper2_NRC_Emotion_Lexicon.pdf  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/._NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Older Versions/readme.txt  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Older Versions/._readme.txt  \n",
            "  inflating: NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Older Versions/NRC-Emotion-Lexicon-v0.92-InManyLanguages.xlsx  \n",
            "  inflating: __MACOSX/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/Older Versions/._NRC-Emotion-Lexicon-v0.92-InManyLanguages.xlsx  \n"
          ]
        }
      ],
      "source": [
        "# Downloading the Lexicon Data\n",
        "!curl https://saifmohammad.com/WebDocs/Lexicons/NRC-Emotion-Lexicon.zip >> NRC-Emotion-Lexicon.zip\n",
        "!unzip NRC-Emotion-Lexicon.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S10vztVIByzL",
        "outputId": "c3f84bb5-94d1-453f-afdd-f1f854ad70f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      English (en)        Afrikaans (af)     Albanian (sq) Amharic (am)  \\\n",
            "0            aback  uit die veld geslaan             prapa         ተጭኗል   \n",
            "1           abacus                abakus         numërator       abacus   \n",
            "2          abandon               verlaat           braktis           ውጣ   \n",
            "3        abandoned               verlate         braktisur         ተትቷል   \n",
            "4      abandonment             verlating         braktisje         ማቋረጥ   \n",
            "...            ...                   ...               ...          ...   \n",
            "14177         zone                  sone              zonë           ዞን   \n",
            "14178          zoo             dieretuin  kopsht zoologjik         መናፈሻ   \n",
            "14179   zoological           dierkundige         zoologjik       ዞኦሎጂካል   \n",
            "14180      zoology             dierkunde          zoologji         ዞኦሎጂ   \n",
            "14181         zoom               Klik op              zoom          አጉላ   \n",
            "\n",
            "       Arabic (ar)      Armenian (hy) Azeerbaijani (az)     Basque (eu)  \\\n",
            "0       الى الوراء             շեղում             sanki           aback   \n",
            "1        طبلية تاج   անբավարարություն            abacus           abako   \n",
            "2             تخلى               լքել           tərk et   bertan behera   \n",
            "3            مهجور              լքված         tərk etdi  abandonatutako   \n",
            "4        التخلي عن        հրաժարվելով              ləğv        abandono   \n",
            "...            ...                ...               ...             ...   \n",
            "14177        منطقة               գոտի              zona            zona   \n",
            "14178  حديقة حيوان          գազանանոց               zoo       zoologiko   \n",
            "14179       حيواني     կենդանաբանական           zooloji       zoologiko   \n",
            "14180  علم الحيوان  կենդանաբանություն           zooloji         zoology   \n",
            "14181        تكبير         խոշորացում              zoom            zoom   \n",
            "\n",
            "      Belarusian (be)      Bengali (bn)  ... Positive Negative Anger  \\\n",
            "0               ззаду           পশ্চাতে  ...        0        0     0   \n",
            "1               абака  গণনা-যন্ত্রবিশেষ  ...        0        0     0   \n",
            "2        адмовіцца ад        বর্জিত করা  ...        0        1     0   \n",
            "3            закінуты         পরিত্যক্ত  ...        0        1     1   \n",
            "4           пакіданне           বিসর্জন  ...        0        1     1   \n",
            "...               ...               ...  ...      ...      ...   ...   \n",
            "14177            зона             মণ্ডল  ...        0        0     0   \n",
            "14178         заапарк      চিড়িয়াখানা  ...        0        0     0   \n",
            "14179      заалагічны    প্রাণিবিদ্যাগত  ...        0        0     0   \n",
            "14180        заалогія       প্রাণিবিদ্য  ...        0        0     0   \n",
            "14181             зум              জুম্  ...        0        0     0   \n",
            "\n",
            "      Anticipation Disgust Fear Joy Sadness Surprise Trust  \n",
            "0                0       0    0   0       0        0     0  \n",
            "1                0       0    0   0       0        0     1  \n",
            "2                0       0    1   0       1        0     0  \n",
            "3                0       0    1   0       1        0     0  \n",
            "4                0       0    1   0       1        1     0  \n",
            "...            ...     ...  ...  ..     ...      ...   ...  \n",
            "14177            0       0    0   0       0        0     0  \n",
            "14178            0       0    0   0       0        0     0  \n",
            "14179            0       0    0   0       0        0     0  \n",
            "14180            0       0    0   0       0        0     0  \n",
            "14181            0       0    0   0       0        0     0  \n",
            "\n",
            "[14182 rows x 115 columns]\n"
          ]
        }
      ],
      "source": [
        "# Reading data into panda df\n",
        "lexicon = pd.read_excel(\"NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-v0.92-In105Languages-Nov2017Translations.xlsx\")\n",
        "print(lexicon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTte5bIerFLk",
        "outputId": "0104d4eb-ff53-49e5-9a0e-e5e0b79281a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English (en)\n",
            "English (en).1\n"
          ]
        }
      ],
      "source": [
        "# Exploration\n",
        "for i in lexicon.columns:\n",
        "  if \"English\" in i:\n",
        "    print(i)\n",
        "# Note that there are two English columns! We'll drop the second\n",
        "lexicon = lexicon.drop(['English (en).1'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTo66Y_Oq_Jo",
        "outputId": "d251533a-d889-48cb-fc34-e3917ca5672c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           english             afrikaans          albanian amharic  \\\n",
            "0            aback  uit die veld geslaan             prapa    ተጭኗል   \n",
            "1           abacus                abakus         numërator  abacus   \n",
            "2          abandon               verlaat           braktis      ውጣ   \n",
            "3        abandoned               verlate         braktisur    ተትቷል   \n",
            "4      abandonment             verlating         braktisje    ማቋረጥ   \n",
            "...            ...                   ...               ...     ...   \n",
            "14177         zone                  sone              zonë      ዞን   \n",
            "14178          zoo             dieretuin  kopsht zoologjik    መናፈሻ   \n",
            "14179   zoological           dierkundige         zoologjik  ዞኦሎጂካል   \n",
            "14180      zoology             dierkunde          zoologji    ዞኦሎጂ   \n",
            "14181         zoom               Klik op              zoom     አጉላ   \n",
            "\n",
            "            arabic           armenian azeerbaijani          basque  \\\n",
            "0       الى الوراء             շեղում        sanki           aback   \n",
            "1        طبلية تاج   անբավարարություն       abacus           abako   \n",
            "2             تخلى               լքել      tərk et   bertan behera   \n",
            "3            مهجور              լքված    tərk etdi  abandonatutako   \n",
            "4        التخلي عن        հրաժարվելով         ləğv        abandono   \n",
            "...            ...                ...          ...             ...   \n",
            "14177        منطقة               գոտի         zona            zona   \n",
            "14178  حديقة حيوان          գազանանոց          zoo       zoologiko   \n",
            "14179       حيواني     կենդանաբանական      zooloji       zoologiko   \n",
            "14180  علم الحيوان  կենդանաբանություն      zooloji         zoology   \n",
            "14181        تكبير         խոշորացում         zoom            zoom   \n",
            "\n",
            "         belarusian           bengali  ... positive negative anger  \\\n",
            "0             ззаду           পশ্চাতে  ...        0        0     0   \n",
            "1             абака  গণনা-যন্ত্রবিশেষ  ...        0        0     0   \n",
            "2      адмовіцца ад        বর্জিত করা  ...        0        1     0   \n",
            "3          закінуты         পরিত্যক্ত  ...        0        1     1   \n",
            "4         пакіданне           বিসর্জন  ...        0        1     1   \n",
            "...             ...               ...  ...      ...      ...   ...   \n",
            "14177          зона             মণ্ডল  ...        0        0     0   \n",
            "14178       заапарк      চিড়িয়াখানা  ...        0        0     0   \n",
            "14179    заалагічны    প্রাণিবিদ্যাগত  ...        0        0     0   \n",
            "14180      заалогія       প্রাণিবিদ্য  ...        0        0     0   \n",
            "14181           зум              জুম্  ...        0        0     0   \n",
            "\n",
            "      anticipation disgust fear joy sadness surprise trust  \n",
            "0                0       0    0   0       0        0     0  \n",
            "1                0       0    0   0       0        0     1  \n",
            "2                0       0    1   0       1        0     0  \n",
            "3                0       0    1   0       1        0     0  \n",
            "4                0       0    1   0       1        1     0  \n",
            "...            ...     ...  ...  ..     ...      ...   ...  \n",
            "14177            0       0    0   0       0        0     0  \n",
            "14178            0       0    0   0       0        0     0  \n",
            "14179            0       0    0   0       0        0     0  \n",
            "14180            0       0    0   0       0        0     0  \n",
            "14181            0       0    0   0       0        0     0  \n",
            "\n",
            "[14182 rows x 114 columns]\n"
          ]
        }
      ],
      "source": [
        "# Cleaning column names\n",
        "lexicon.rename(columns=lambda x: x.split(\" \")[0], inplace=True)\n",
        "lexicon = lexicon.clean_names()\n",
        "print(lexicon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG-RUQ7GElR-",
        "outputId": "48499c88-cd74-428d-fa24-e4c77a457d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['positive', 'negative', 'anger', 'anticipation', 'disgust', 'fear',\n",
            "       'joy', 'sadness', 'surprise', 'trust', 'word'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Creating Emotions DF from subset of Lexicon\n",
        "emotions = lexicon.iloc[:, -10:]\n",
        "emotions['word'] = lexicon.loc[:, \"english\"]\n",
        "print(emotions.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "7fwzyVk6Tuby",
        "outputId": "b29db7c5-45f3-4df4-89fc-cc7b70bffb09"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bf7d84bf5743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3359\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(0        False\n1        False\n2        False\n3        False\n4        False\n         ...  \n14177    False\n14178    False\n14179    False\n14180    False\n14181    False\nName: word, Length: 14182, dtype: bool, slice(None, None, None))' is an invalid key"
          ]
        }
      ],
      "source": [
        "emotions[emotions['word'] == 'sad', :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSYiDGeBtM85"
      },
      "outputs": [],
      "source": [
        "# How many words are positive, negative, angry, etc.? \n",
        "print(\"Words in Lexicon:\", len(emotions))\n",
        "for emotion in emotions:\n",
        "  if emotion != \"word\":\n",
        "    print(emotion + \": \", end=\"\")\n",
        "    print(emotions.groupby(emotion).size()[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9lJOhiFiMPT"
      },
      "outputs": [],
      "source": [
        "emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j40iiAYVhaBK"
      },
      "outputs": [],
      "source": [
        "# Saving emotions dataset as csv\n",
        "emotions.to_csv(\"emotions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tToJym5tuLf",
        "outputId": "2d68936f-2921-4bab-9f7f-bd5c0dc35584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['english', 'afrikaans', 'albanian', 'amharic', 'arabic', 'armenian',\n",
            "       'azeerbaijani', 'basque', 'belarusian', 'bengali',\n",
            "       ...\n",
            "       'turkish', 'ukrainian', 'urdu', 'uzbek', 'vietnamese', 'welsh', 'xhosa',\n",
            "       'yiddish', 'yoruba', 'zulu'],\n",
            "      dtype='object', length=104)\n"
          ]
        }
      ],
      "source": [
        "# Creating translation DF from subset of Lexicon\n",
        "translation = lexicon.iloc[:, :-10]\n",
        "print(translation.columns)\n",
        "translation = translation.dropna()\n",
        "translation.isnull().values.any()\n",
        "\n",
        "translation.to_csv(\"translation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKT_so1BhObc"
      },
      "outputs": [],
      "source": [
        "for c in translation.columns:\n",
        "  print(f\"\\\"{c.capitalize()}\\\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTACjNBC6iNy"
      },
      "outputs": [],
      "source": [
        "!pip install ipdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgLcd85PvalX"
      },
      "outputs": [],
      "source": [
        "# Pulling synonym dataset from kaggle; will need a kaggle.json api key\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!kaggle datasets download duketemon/wordnet-synonyms\n",
        "!unzip wordnet-synonyms.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxI-f4VmKztc"
      },
      "outputs": [],
      "source": [
        "syn = pd.read_csv(\"synonyms.csv\")\n",
        "syn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z83zLdwx5B9p"
      },
      "outputs": [],
      "source": [
        "# Number of each part of speech\n",
        "print(syn.groupby(['part_of_speech']).size())\n",
        "syn['synonyms'].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiW6UVoP1ahd"
      },
      "source": [
        "The dataset is pretty messy; a few things need to be cleaned up. \n",
        "\n",
        "1.   First, the synonyms are bunched up into one row, separated by semicolons. We want each row to be one word and one synonym, not one word to many synonyms. \n",
        "2.   Second, the word itself often appears in the synonyms column. However sometimes it doesn't and a word doesn't have any synonyms at all! We have to drop these rows too. \n",
        "3. Lastly, sometimes the words are split on the pipe symbol '|' rather than semicolons.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZTMWoYx1Y-F"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "%pdb off\n",
        "# def runner():\n",
        "\n",
        "syn.dropna(inplace=True)\n",
        "# counter = 0\n",
        "synonyms = pd.DataFrame(columns = syn.columns) \n",
        "def spl(series):\n",
        "  # nonlocal counter\n",
        "  syns = re.split(';|\\|',series['synonyms'])\n",
        "  # counter += 1\n",
        "  # if counter % 1000 == 0:\n",
        "    # print(counter)\n",
        "  for s in syns:\n",
        "    # synonyms.append({'word': series['lemma'], 'part_of_speech': series['part_of_speech'], 'synonym': s}, ignore_index=True)\n",
        "    synonyms.loc[len(synonyms.index)] = [series['lemma'], series['part_of_speech'], s]\n",
        "    # print(synonyms)\n",
        "\n",
        "syn.apply(spl, axis=1)\n",
        "print(synonyms)\n",
        "  # synonyms = pd.DataFrame(columns = ['word', 'synonym'])\n",
        "  # spl()\n",
        "  # syn[\"synonyms\"].apply(lambda x: re.split(';|\\|',x))\n",
        "  # syn\n",
        "  # type(syn['synonyms'])\n",
        "  # print(syn.dtypes)\n",
        "  # syn.groupby(['part_of_speech']).size()\n",
        "# runner()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCldeIbILGwM"
      },
      "outputs": [],
      "source": [
        "synonyms.to_pickle(\"./syn.pkl\")  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "450.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
